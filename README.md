# Real-Time IoT Analytics Pipeline with Kafka, Spark, Docker, and HDFS

![IoT Pipeline](https://img.shields.io/badge/IoT-Real--Time--Analytics-blue) ![Kafka](https://img.shields.io/badge/Apache-Kafka-orange) ![Spark](https://img.shields.io/badge/Apache-Spark-red) ![Docker](https://img.shields.io/badge/Docker-Ready-brightgreen) ![HDFS](https://img.shields.io/badge/HDFS-Storage-yellow)

ğŸ‰ Bienvenue dans le projet **Real-Time IoT Analytics Pipeline** ! Ce projet met en Å“uvre une architecture robuste pour le traitement des donnÃ©es en temps rÃ©el Ã  l'aide des technologies modernes comme Kafka, Spark Streaming, HDFS, et Docker. Une interface web Flask est utilisÃ©e pour visualiser les donnÃ©es traitÃ©es.

---

## ğŸ“Œ **Description**

Ce projet est conÃ§u pour dÃ©montrer comment :
- **Collecter** des donnÃ©es en temps rÃ©el Ã  partir de capteurs IoT ou d'autres sources.
- **Traiter** ces donnÃ©es en temps rÃ©el avec Apache Spark Streaming.
- **Stocker** les donnÃ©es transformÃ©es dans HDFS pour une analyse ultÃ©rieure.
- **Visualiser** les flux de donnÃ©es et les rÃ©sultats dans une interface web conviviale.

### **Exemple de scÃ©nario d'utilisation**
Imaginez un rÃ©seau de capteurs surveillant la tempÃ©rature et l'humiditÃ© dans une usine. Les donnÃ©es transmises sont collectÃ©es en temps rÃ©el par Kafka, analysÃ©es via Spark Streaming (ex. identification d'anomalies), stockÃ©es dans HDFS, puis affichÃ©es dans un tableau de bord interactif.

---

## ğŸ› ï¸ **Technologies UtilisÃ©es**
Voici les principales technologies utilisÃ©es dans ce projet :
| Tech | Description |
|------|-------------|
| **Apache Kafka** | Collecte et transmet les donnÃ©es en temps rÃ©el. |
| **Apache Spark Streaming** | Traitement des flux de donnÃ©es en temps rÃ©el. |
| **HDFS** | Stockage distribuÃ© pour les donnÃ©es traitÃ©es. |
| **Docker** | Conteneurisation des diffÃ©rents services pour un dÃ©ploiement simplifiÃ©. |
| **Flask** | Interface web pour la visualisation des donnÃ©es. |

---

## ğŸš€ **FonctionnalitÃ©s**
- **Traitement des donnÃ©es en temps rÃ©el** : Analyse des flux de donnÃ©es en continu.
- **Stockage distribuÃ©** : Conservation des donnÃ©es traitÃ©es pour des analyses futures.
- **Visualisation intuitive** : Affichage des donnÃ©es en temps rÃ©el Ã  l'aide de graphiques et tableaux.
- **ExtensibilitÃ©** : Facile Ã  adapter pour des cas d'utilisation spÃ©cifiques (IoT, industrie, santÃ©, etc.).

---

## ğŸ“‚ **Structure du Projet**
```plaintext
ğŸ“ Real-Time-IoT-Analytics-Pipeline
â”œâ”€â”€ ğŸ“‚ kafka/                # Configuration et scripts Kafka.
â”œâ”€â”€ ğŸ“‚ spark/                # Scripts de traitement Spark Streaming.
â”œâ”€â”€ ğŸ“‚ hdfs/                 # Configuration pour le stockage HDFS.
â”œâ”€â”€ ğŸ“‚ docker/               # Fichiers Docker pour chaque service.
â”œâ”€â”€ ğŸ“‚ flask_app/            # Application Flask pour la visualisation.
â”œâ”€â”€ ğŸ“‚ data/                 # DonnÃ©es d'entrÃ©e et de test.
â”œâ”€â”€ ğŸ“œ docker-compose.yml    # Fichier Docker Compose pour dÃ©marrer l'ensemble du pipeline.
â””â”€â”€ ğŸ“œ README.md             # Documentation du projet.
```

---

## ğŸ”§ **Installation et Configuration**

### **PrÃ©requis**
- Docker et Docker Compose installÃ©s
- Python 3.7+ installÃ©

### **Ã‰tapes pour exÃ©cuter le projet**
1. **Clonez le dÃ©pÃ´t** :
   ```bash
   git clone https://github.com/BoubaAhmed/Real-Time-IoT-Analytics-Pipeline-with-Kafka-Spark-Docker-HDFS.git
   cd Real-Time-IoT-Analytics-Pipeline-with-Kafka-Spark-Docker-HDFS
   ```

2. **Lancez les conteneurs Docker** :
   ```bash
   docker-compose up --build
   ```

3. **AccÃ©dez Ã  l'interface Flask** :
   - Ouvrez votre navigateur et allez Ã  [http://localhost:5000](http://localhost:5000).

4. **Testez avec des donnÃ©es d'exemple** :
   - Envoyez des donnÃ©es vers Kafka Ã  l'aide des scripts fournis dans le dossier `kafka/`.

---

## ğŸ“Š **Visualisation des DonnÃ©es**
L'application Flask offre une interface utilisateur simple et intuitive pour :
- Suivre les donnÃ©es des capteurs en temps rÃ©el.
- Visualiser des graphiques et des tableaux.
- Configurer des alertes pour des seuils personnalisÃ©s.

---

## ğŸ›¡ï¸ **Contributions**
Les contributions sont les bienvenues ! Si vous souhaitez amÃ©liorer ce projet ou ajouter de nouvelles fonctionnalitÃ©s :
1. **Forkez** le dÃ©pÃ´t.
2. CrÃ©ez une branche pour vos modifications :
   ```bash
   git checkout -b feature/nom-de-la-fonctionnalite
   ```
3. Soumettez une Pull Request ğŸ‰.

---

## ğŸ“„ **Licence**
Ce projet est sous licence MIT. Consultez le fichier [LICENSE](LICENSE) pour plus d'informations.

---

## ğŸ“ **Contact**
Pour toute question ou suggestion, n'hÃ©sitez pas Ã  me contacter via [GitHub](https://github.com/BoubaAhmed).

---

ğŸŒŸ **Si vous aimez ce projet, n'oubliez pas de lui donner une Ã©toile â­ sur GitHub !**